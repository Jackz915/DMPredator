_target_: src.models.SeqStructureMultiTaskModel.SeqStructureMultiTaskModel

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 1e-4
  weight_decay: 1e-12

scheduler: # note: leaving `scheduler` empty will result in a learning-rate scheduler not being used
  # _target_: torch.optim.lr_scheduler.StepLR
  # _partial_: true
  # step_size: ${...trainer.min_epochs} // 8  # note: using literal evalution manually until Hydra natively supports this functionality
  # gamma: 0.9
  # last_epoch: -1

defaults:
  - bert_cfg: bert.yaml
  - graph_cfg: mpnn.yaml
  - inter_cfg: inter.yaml
  - task_cfg: task.yaml

seed: ${..seed}
